# Clinic Template Module

## ğŸ“Œ ëª¨ë“ˆ ê°œìš”
Clinic í…œí”Œë¦¿ì€ **ë³‘ì› ë° ì˜ë£Œ ì •ë³´ RAG ì‹œìŠ¤í…œ**ì„ êµ¬í˜„í•©ë‹ˆë‹¤. FAISS ë²¡í„° ê²€ìƒ‰ê³¼ GPT-4oë¥¼ ê²°í•©í•˜ì—¬ ì˜ë£Œì§„/ë³‘ì› ê´€ë ¨ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ—ï¸ ì‹¤ì œ êµ¬ì¡°

```
template/clinic/
â”œâ”€â”€ clinic_template_impl.py  # ë³‘ì› ì •ë³´ RAG ë¡œì§ êµ¬í˜„
â””â”€â”€ common/
    â””â”€â”€ clinic_serialize.py  # ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ
```

## ğŸ¤– í•µì‹¬ ê¸°ëŠ¥ ë¶„ì„

### 1. ClinicTemplateImpl ì´ˆê¸°í™”
```python
class ClinicTemplateImpl(ClinicTemplate):
    def init(self, config):
        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        self.index = faiss.read_index(os.path.join(base_path, "faiss_index", "index.faiss"))
        
        # ë¬¸ì„œ ID ë§¤í•‘ ë¡œë“œ
        with open(os.path.join(base_path, "doc_ids.json"), "r", encoding="utf-8") as f:
            self.doc_ids = json.load(f)
            
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embedding_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # í‚¤ì›Œë“œ ì¸ë±ìŠ¤ ë¡œë“œ
        with open("resources/vectorDB/treatment/RAG_Output/faiss_medical/keyword_index.json") as f:
            self.keyword_index = json.load(f)
```

**ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” í™˜ê²½ë³€ìˆ˜**:
- `CLINIC_VECTORDB_BASE` - FAISS ì¸ë±ìŠ¤ì™€ ë¬¸ì„œ ID íŒŒì¼ ê²½ë¡œ
- `CLINIC_VECTORDB_DOCS` - ì²˜ë¦¬ëœ ë¬¸ì„œ íŒŒì¼ë“¤ ê²½ë¡œ  
- `OPENAI_API_KEY` - OpenAI API í‚¤

### 2. RAG ì²˜ë¦¬ í”Œë¡œìš°
```python
async def on_clinic_ask_req(self, client_session, request: ClinicAskRequest) -> ClinicAskResponse:
    question = request.question
    
    # 1. ì§ˆë¬¸ ì„ë² ë”©
    q_vector = self.embedding_model.encode(question)
    q_vector = np.array([q_vector]).astype("float32")
    
    # 2. FAISS ê²€ìƒ‰ (top 3)
    D, I = self.index.search(q_vector, k=3)
    
    # 3. ë¬¸ì„œ chunk ë¡œë“œ
    retrieved_texts = []
    for idx in I[0]:
        if idx < len(self.doc_ids):
            doc_filename = self.doc_ids[idx]
            if not doc_filename.endswith(".txt"):
                doc_filename += ".txt"
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
    
    context = "\n\n".join(retrieved_texts)
```

## ğŸ” í‚¤ì›Œë“œ Fallback ì‹œìŠ¤í…œ

### í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì •ì œ
```python
# í•œêµ­ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ
raw_keywords = re.findall(r"[ê°€-í£a-zA-Z]{2,}", question)

# ì¡°ì‚¬ ì œê±°
particles = {"ì€", "ëŠ”", "ì´", "ê°€", "ì„", "ë¥¼", "ì—", "ì˜", "ìœ¼ë¡œ", "ì—ì„œ", "ë„", "ë§Œ", "ì™€", "ê³¼", "ë³´ë‹¤"}
cleaned_keywords = []
for word in raw_keywords:
    for p in particles:
        if word.endswith(p) and len(word) > len(p):
            word = word[: -len(p)]
            break
    cleaned_keywords.append(word)
```

### Fallback ê²€ìƒ‰ ë¡œì§
```python
# í‚¤ì›Œë“œê°€ ì»¨í…ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ í‚¤ì›Œë“œ ì¸ë±ìŠ¤ì—ì„œ ì¶”ê°€ ê²€ìƒ‰
if not any(k in context for k in question_keywords):
    fallback_limit = 4
    fallback_added = 0
    for kw in question_keywords:
        for fname in self.keyword_index.get(kw, []):
            # ì¶”ê°€ ë¬¸ì„œ ë¡œë“œí•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€
```

## ğŸ“Š ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ

### ClinicAskRequest
```python
class ClinicAskRequest(BaseRequest):
    question: str  # ë³‘ì›/ì˜ë£Œì§„ ê´€ë ¨ ì§ˆë¬¸
```

### ClinicAskResponse
```python
class ClinicAskResponse(BaseResponse):
    answer: str    # GPTê°€ ìƒì„±í•œ ì‘ë‹µ
```

## ğŸ§  GPT-4o í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ

### ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” í”„ë¡¬í”„íŠ¸
```python
prompt = f"""
ë‹¹ì‹ ì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜ë£Œ ì „ë¬¸ ìƒë‹´ AIì…ë‹ˆë‹¤.

ì•„ë˜ [ë¬¸ì„œ ë‚´ìš©]ì— ê¸°ë°˜í•˜ì—¬ [ì§ˆë¬¸]ì— ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
ë¬¸ì„œì— ì •ë³´ê°€ ì—†ìœ¼ë©´ "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë§í•˜ì„¸ìš”.
ì ˆëŒ€ ì •ë³´ë¥¼ ì¶”ì¸¡í•˜ê±°ë‚˜ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

[ë¬¸ì„œ ë‚´ìš©]
{context}

[ì§ˆë¬¸]
{question}

[ë‹µë³€]
"""
```

### GPT í˜¸ì¶œ íŒŒë¼ë¯¸í„°
```python
response = self.client.chat.completions.create(
    model="gpt-4o",          # GPT-4o ëª¨ë¸ ì‚¬ìš©
    messages=[
        {"role": "system", "content": "ë„ˆëŠ” ì˜ë£Œ ì „ë¬¸ ìƒë‹´ AIì•¼."},
        {"role": "user", "content": prompt}
    ],
    temperature=0.2,         # ì¼ê´€ì„± ìœ„í•œ ë‚®ì€ temperature
    max_tokens=512,          # ì‘ë‹µ ê¸¸ì´ ì œí•œ
)
```

## âš¡ ì„±ëŠ¥ ìµœì í™”

### 1. ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
```python
MAX_CONTEXT_CHARS = 10_000
if len(context) > MAX_CONTEXT_CHARS:
    context = context[:MAX_CONTEXT_CHARS] + "\n\n...(ìƒëµë¨)"
```

### 2. íŒŒì¼ ì¡´ì¬ ê²€ì¦
```python
if os.path.exists(doc_path):
    with open(doc_path, "r", encoding="utf-8") as f:
        content = f.read()
        if content.strip():
            retrieved_texts.append(content)
        else:
            print(f"íŒŒì¼ì€ ìˆìœ¼ë‚˜ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŒ: {doc_filename}")
```

## ğŸ”— ì˜ì¡´ì„±

### ì‚¬ìš©í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬
- `sentence_transformers` - SentenceTransformer ì„ë² ë”©
- `faiss` - ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
- `openai` - GPT-4o API í˜¸ì¶œ
- `numpy` - ë²¡í„° ì—°ì‚°
- `json` - JSON íŒŒì¼ ì²˜ë¦¬
- `os` - í™˜ê²½ë³€ìˆ˜ ë° íŒŒì¼ ì‹œìŠ¤í…œ
- `re` - ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­
- `dotenv` - í™˜ê²½ë³€ìˆ˜ ë¡œë“œ

### ë°ì´í„° íŒŒì¼ êµ¬ì¡°
- `{CLINIC_VECTORDB_BASE}/faiss_index/index.faiss` - FAISS ë²¡í„° ì¸ë±ìŠ¤
- `{CLINIC_VECTORDB_BASE}/doc_ids.json` - ë¬¸ì„œ ID ë§¤í•‘
- `{CLINIC_VECTORDB_DOCS}/*.txt` - ì²˜ë¦¬ëœ ë¬¸ì„œ í…ìŠ¤íŠ¸ íŒŒì¼ë“¤
- `resources/vectorDB/treatment/RAG_Output/faiss_medical/keyword_index.json` - í‚¤ì›Œë“œ ë§¤í•‘

## ğŸ’­ ì‹¤ì œ ì½”ë“œì˜ íŠ¹ì§•

1. **ì´ì¤‘ ê²€ìƒ‰ ì‹œìŠ¤í…œ**: FAISS ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ fallback
2. **í•œêµ­ì–´ ìµœì í™”**: ì¡°ì‚¬ ì œê±°ë¥¼ í†µí•œ í‚¤ì›Œë“œ ì •ì œ
3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**: ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œìœ¼ë¡œ í† í° ì‚¬ìš©ëŸ‰ ì œì–´
4. **ì—ëŸ¬ ì•ˆì •ì„±**: íŒŒì¼ ì¡´ì¬ í™•ì¸ ë° ë¹ˆ íŒŒì¼ ì²˜ë¦¬
5. **ì •í™•ì„± ìš°ì„ **: ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€, ì¶”ì¸¡ ê¸ˆì§€ í”„ë¡¬í”„íŠ¸

ì´ ëª¨ë“ˆì€ **ì˜ë£Œ ì •ë³´ ì „ë¬¸ê°€**ë¡œì„œ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ë³‘ì›/ì˜ë£Œì§„ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” **RAG ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤.