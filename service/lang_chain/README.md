# LangChain Service Module

## ğŸ“Œ ëª¨ë“ˆ ê°œìš”
LangChain ì„œë¹„ìŠ¤ëŠ” ì˜ë£Œ ë„ë©”ì¸ë³„ AI ì‘ë‹µ ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤. RAG(Retrieval-Augmented Generation) íŒ¨í„´ì„ í†µí•´ ë²¡í„° ê²€ìƒ‰ê³¼ LLMì„ ê²°í•©í•œ ì§€ëŠ¥í˜• ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ ì™œ ì´ íŒŒì¼ë“¤ì´ í•¨ê»˜ ë¬¶ì—¬ìˆëŠ”ê°€?

### íŒŒì¼ êµ¬ì„±ê³¼ ì—­í• 
```
lang_chain/
â”œâ”€â”€ category_classifer.py           # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ + ì±—ë´‡ (í´ë˜ìŠ¤ ê¸°ë°˜)
â”œâ”€â”€ drug_lang_chain.py              # ì•½í’ˆ ì •ë³´ RAG (í´ë˜ìŠ¤ ê¸°ë°˜)
â”œâ”€â”€ emergency_support_lang_chain.py # ì‘ê¸‰ ì§€ì› RAG (í•¨ìˆ˜ ê¸°ë°˜)
â””â”€â”€ internal_external_lang_chain.py # ë‚´ê³¼/ì™¸ê³¼ RAG (í•¨ìˆ˜ ê¸°ë°˜, emergencyì™€ ë™ì¼)
```

**ê³µí†µ ê¸°ìˆ  ìŠ¤íƒ**:
- `SentenceTransformer("jhgan/ko-sroberta-multitask")`: í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸
- `FAISS`: ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
- `ChatOpenAI(model="gpt-4o-mini")`: OpenAI LLM
- `LangChain`: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ê³¼ ì²´ì¸ êµ¬ì„±

## ğŸ—ï¸ ì‹¤ì œ êµ¬í˜„ ë¶„ì„

### 1. Category Classifier (ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê¸°)

```python
class Category_Classifier:
    def __init__(self):
        # ë²¡í„° DB ë¡œë“œ (pickle, torch íŒŒì¼)
        self.category_texts, self.category_categories, self.category_embeddings = self.load_vector_db()
        # ì •ê·œí™”ëœ ì„ë² ë”©
        self.category_embeddings_norm = self.normalize(self.category_embeddings.numpy())
        # í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸
        self.embedder = SentenceTransformer("jhgan/ko-sroberta-multitask")
        # ë‘ ê°€ì§€ LLM ì‚¬ìš©
        self.chatbot_llm = ChatOpenAI(...)  # LangChainìš©
        self.client = OpenAI(...)           # ë¶„ë¥˜ ì „ìš©
```

**íŠ¹ì§•**:
- ë‘ ê°€ì§€ LLM í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (LangChain + OpenAI SDK)
- pickleê³¼ torch íŒŒì¼ë¡œ ë²¡í„° DB ê´€ë¦¬
- ë²¡í„° ì •ê·œí™”ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ìµœì í™”

### 2. Drug Vector Store (ì•½í’ˆ ì •ë³´)

```python
class Vector_store:
    def __init__(self, api_key, chunk_path, index_path, ...):
        self.chunks = self.load_chunks(chunk_path)      # í…ìŠ¤íŠ¸ ì²­í¬
        self.index = self.load_faiss_index(index_path)  # FAISS ì¸ë±ìŠ¤
        self.embedding_model = self.load_embedding_model(...)
        self.llm = self.connect_gpt(...)
        self.rag_chain = self.build_rag_chain()
```

**íŠ¹ì§•**:
- í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì²­í¬ ë¡œë“œ
- FAISS ì¸ë±ìŠ¤ íŒŒì¼ ì‚¬ìš©
- RAG ì²´ì¸ ë¹Œë“œ íŒ¨í„´

### 3. Emergency & Internal/External (ì‘ê¸‰/ë‚´ì™¸ê³¼)

```python
# í•¨ìˆ˜ ê¸°ë°˜ êµ¬í˜„
def load_embedding_model():
    return SentenceTransformer("jhgan/ko-sroberta-multitask")

def load_faiss_index(index_path: str):
    return faiss.read_index(index_path)

async def get_rag_answer_async(question, index, chunks, embed_model, rag_chain):
    # 1. ê²€ìƒ‰
    top_chunks = search_similar_chunks(question, index, chunks, embed_model)
    # 2. ìƒì„±
    answer = await rag_chain.ainvoke({"context": context, "question": question})
```

**íŠ¹ì§•**:
- í•¨ìˆ˜ ê¸°ë°˜ ëª¨ë“ˆí™”
- ë¹„ë™ê¸° ì²˜ë¦¬ (`async/await`)
- emergencyì™€ internal_externalì€ **ì™„ì „íˆ ë™ì¼í•œ ì½”ë“œ**

## ğŸ’¡ í•µì‹¬ êµ¬í˜„ íŒ¨í„´

### 1. RAG ì²˜ë¦¬ íë¦„
```python
# 1. ì§ˆë¬¸ì„ ë²¡í„°ë¡œ ë³€í™˜
embedding = model.encode([question])

# 2. FAISSë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
_, indices = index.search(embedding, top_k)

# 3. ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
context = "\n".join(top_chunks)

# 4. LLMì— ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ ì „ë‹¬
answer = await rag_chain.ainvoke({"context": context, "question": question})
```

### 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
```python
# ì˜ë£Œ ì „ë¬¸ í”„ë¡¬í”„íŠ¸
"ë‹¹ì‹ ì€ ì˜í•™ì „ê³µì„ í•˜ì—¬ ì €í¬ì˜ ì§ˆë¬¸ì— ëŒ€ë‹µì„ ì˜ í•´ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤"
"ë§Œì•½ ì§„ë£Œí˜¹ì€ ì•½, ì˜í•™ê³¼ ê´€ë ¨ì´ ì—†ëŠ” ì§ˆë¬¸ì´ë©´ ì§ˆë¬¸ì´ ì£¼ì œì™€ ë‹¤ë¥´ë‹¤ê³  í•˜ë©´ ë©ë‹ˆë‹¤"
```

### 3. ë²¡í„° ì •ê·œí™”
```python
def normalize(self, v):
    return v / (np.linalg.norm(v, axis=-1, keepdims=True) + 1e-8)
```
- L2 ì •ê·œí™”ë¡œ ë‹¨ìœ„ ë²¡í„° ìƒì„±
- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ìµœì í™”

## ğŸ”„ ë°ì´í„° í”Œë¡œìš°

```
ì‚¬ìš©ì ì§ˆë¬¸
    â†“
ì„ë² ë”© ìƒì„± (SentenceTransformer)
    â†“
FAISS ê²€ìƒ‰ (top_k=3)
    â†“
ì²­í¬ ì¶”ì¶œ
    â†“
í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    â†“
ChatGPT í˜¸ì¶œ (gpt-4o-mini)
    â†“
ì‘ë‹µ ë°˜í™˜
```

## âš¡ ì‹¤ì œ ì‚¬ìš©ëœ ìµœì í™”

### 1. ë²¡í„° ê²€ìƒ‰ ìµœì í™”
- `float32` íƒ€ì… ë³€í™˜ìœ¼ë¡œ FAISS í˜¸í™˜ì„± í™•ë³´
- top_k=3ìœ¼ë¡œ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë§Œ ì„ íƒ

### 2. ë¹„ë™ê¸° ì²˜ë¦¬
- `ainvoke` ì‚¬ìš©ìœ¼ë¡œ non-blocking ì²˜ë¦¬
- FastAPIì™€ì˜ ë¹„ë™ê¸° í†µí•©

### 3. ë¦¬ì†ŒìŠ¤ ì¬ì‚¬ìš©
- ëª¨ë¸ê³¼ ì¸ë±ìŠ¤ë¥¼ í•œ ë²ˆë§Œ ë¡œë“œ
- í´ë˜ìŠ¤/ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ì¬ì‚¬ìš©

## ğŸ“Š ì‹¤ì œ íŒŒì¼ êµ¬ì¡°ì™€ ë°ì´í„°

### ë²¡í„° DB íŒŒì¼ í˜•ì‹
- **Category**: `texts.pkl`, `categories.pkl`, `embeddings.pt`
- **Drug/Emergency**: `*.txt` (ì²­í¬), `*.index` (FAISS)

### í™˜ê²½ ë³€ìˆ˜ ì‚¬ìš©
```python
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
CATEGORY_VECTORDB = os.getenv('CATEGORY_VECTORDB')
```

## ğŸ“ ì½”ë“œì—ì„œ í™•ì¸ëœ ì„¤ê³„ ì˜ë„

1. **ë„ë©”ì¸ ë¶„ë¦¬**: ê° ì˜ë£Œ ë¶„ì•¼ë³„ ë…ë¦½ëœ íŒŒì¼
2. **êµ¬í˜„ ë°©ì‹ ë‹¤ì–‘ì„±**: í´ë˜ìŠ¤ ê¸°ë°˜ vs í•¨ìˆ˜ ê¸°ë°˜
3. **ì½”ë“œ ì¬ì‚¬ìš©**: emergencyì™€ internal_external ë™ì¼ ì½”ë“œ
4. **í•œêµ­ì–´ íŠ¹í™”**: ko-sroberta-multitask ëª¨ë¸ ì‚¬ìš©
5. **ê²½ëŸ‰ ëª¨ë¸**: gpt-4o-minië¡œ ë¹„ìš© ìµœì í™”

## ğŸ”— ì‹¤ì œ ì˜ì¡´ì„±

### ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
- `sentence_transformers`: ì„ë² ë”© ìƒì„±
- `faiss`: ë²¡í„° ê²€ìƒ‰
- `langchain_core`, `langchain_openai`: LLM ì²´ì¸
- `openai`: OpenAI API ì§ì ‘ í˜¸ì¶œ
- `numpy`, `torch`, `pickle`: ë°ì´í„° ì²˜ë¦¬

### ë¦¬ì†ŒìŠ¤ ì˜ì¡´
- `resources/vectorDB/`: ì‹¤ì œ ë²¡í„° ë°ì´í„° ì €ì¥ ìœ„ì¹˜
- `.env`: API í‚¤ ë° ê²½ë¡œ ì„¤ì •

## âš ï¸ ì½”ë“œì—ì„œ ë°œê²¬ëœ ì£¼ì˜ì‚¬í•­

1. **ì¤‘ë³µ ì½”ë“œ**: emergencyì™€ internal_external ì™„ì „ ë™ì¼
2. **í˜¼ì¬ëœ ë°©ì‹**: í´ë˜ìŠ¤ì™€ í•¨ìˆ˜ ê¸°ë°˜ í˜¼ìš©
3. **ì—ëŸ¬ ì²˜ë¦¬ ë¶€ì¬**: íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬ ì—†ìŒ
4. **í•˜ë“œì½”ë”©ëœ ê°’**: top_k=3, temperature=0 ë“±